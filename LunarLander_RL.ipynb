{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a87f008708034826a08a55aa54c656e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_929755c06eac4195afe8c016c921cc1a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6098f7fafbbf450d9f0f8dc0960f26f6",
              "IPY_MODEL_423062d6eb5a463b89dc1297cbdbe438"
            ]
          },
          "model_module_version": "1.5.0"
        },
        "929755c06eac4195afe8c016c921cc1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "6098f7fafbbf450d9f0f8dc0960f26f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_84ed7764c8624281874c0e4b809c6bfc",
            "_dom_classes": [],
            "description": "  0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 1000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9d0ddab78ac842f199a9701f4f64b855"
          },
          "model_module_version": "1.5.0"
        },
        "423062d6eb5a463b89dc1297cbdbe438": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d8400b6a99504006a6f08e2cc8c49299",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/1000 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7a9d8a47b5914d29ac72972301049e44"
          },
          "model_module_version": "1.5.0"
        },
        "84ed7764c8624281874c0e4b809c6bfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "9d0ddab78ac842f199a9701f4f64b855": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "d8400b6a99504006a6f08e2cc8c49299": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "7a9d8a47b5914d29ac72972301049e44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fp30SB4bxeQb"
      },
      "source": [
        "# **Homework 12 - Reinforcement Learning**\n",
        "\n",
        "若有任何問題，歡迎來信至助教信箱 ntu-ml-2021spring-ta@googlegroups.com\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXsnCWPtWSNk"
      },
      "source": [
        "## 前置作業\n",
        "\n",
        "首先我們需要安裝必要的系統套件及 PyPi 套件。\n",
        "gym 這個套件由 OpenAI 所提供，是一套用來開發與比較 Reinforcement Learning 演算法的工具包（toolkit）。\n",
        "而其餘套件則是為了在 Notebook 中繪圖所需要的套件。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e2bScpnkVbv",
        "outputId": "5ae40ede-4227-4ed1-efe2-87e21c737429"
      },
      "source": [
        "!apt update\n",
        "!apt install python-opengl xvfb -y\n",
        "!pip install gym[box2d]==0.18.3 pyvirtualdisplay tqdm numpy==1.19.5 torch==1.8.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com (91.18\u001b[0m\u001b[33m\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.152)\u001b[0m\r                                                                               \rGet:2 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "\u001b[33m\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.152)\u001b[0m\r                                                                               \rIgn:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\u001b[33m\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.152)\u001b[0m\r                                                                               \rIgn:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\u001b[33m\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.152)\u001b[0m\r                                                                               \rGet:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [697 B]\n",
            "\u001b[33m\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.152)\u001b[0m\u001b[33m\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.152)\u001b[0m\r                                                                               \rHit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Hit:8 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:12 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Ign:13 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages\n",
            "Get:13 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [599 kB]\n",
            "Get:14 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,185 kB]\n",
            "Hit:17 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:18 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,415 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,185 kB]\n",
            "Get:20 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [40.9 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,619 kB]\n",
            "Fetched 9,312 kB in 3s (3,395 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "47 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "Suggested packages:\n",
            "  libgle3\n",
            "The following NEW packages will be installed:\n",
            "  python-opengl xvfb\n",
            "0 upgraded, 2 newly installed, 0 to remove and 47 not upgraded.\n",
            "Need to get 1,281 kB of archives.\n",
            "After this operation, 7,686 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python-opengl all 3.1.0+dfsg-1 [496 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 xvfb amd64 2:1.19.6-1ubuntu4.9 [784 kB]\n",
            "Fetched 1,281 kB in 1s (960 kB/s)\n",
            "Selecting previously unselected package python-opengl.\n",
            "(Reading database ... 160772 files and directories currently installed.)\n",
            "Preparing to unpack .../python-opengl_3.1.0+dfsg-1_all.deb ...\n",
            "Unpacking python-opengl (3.1.0+dfsg-1) ...\n",
            "Selecting previously unselected package xvfb.\n",
            "Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.9_amd64.deb ...\n",
            "Unpacking xvfb (2:1.19.6-1ubuntu4.9) ...\n",
            "Setting up python-opengl (3.1.0+dfsg-1) ...\n",
            "Setting up xvfb (2:1.19.6-1ubuntu4.9) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Collecting gym[box2d]==0.18.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/db/816fd52c0c196b6799e89d1f65b6c74fead2707cf7d447f3f354edfa7a44/gym-0.18.3.tar.gz (1.6MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 7.8MB/s \n",
            "\u001b[?25hCollecting pyvirtualdisplay\n",
            "  Downloading https://files.pythonhosted.org/packages/79/30/e99e0c480a858410757e7516958e149285ea08ed6c9cfe201ed0aa12cee2/PyVirtualDisplay-2.2-py3-none-any.whl\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.41.1)\n",
            "Requirement already satisfied: numpy==1.19.5 in /usr/local/lib/python3.7/dist-packages (1.19.5)\n",
            "Collecting torch==1.8.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/74/6fc9dee50f7c93d6b7d9644554bdc9692f3023fa5d1de779666e6bf8ae76/torch-1.8.1-cp37-cp37m-manylinux1_x86_64.whl (804.1MB)\n",
            "\u001b[K     |████████████████████████████████| 804.1MB 22kB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym[box2d]==0.18.3) (1.4.1)\n",
            "Requirement already satisfied: pyglet<=1.5.15,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym[box2d]==0.18.3) (1.5.0)\n",
            "Requirement already satisfied: Pillow<=8.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[box2d]==0.18.3) (7.1.2)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[box2d]==0.18.3) (1.3.0)\n",
            "Collecting box2d-py~=2.3.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/34/da5393985c3ff9a76351df6127c275dcb5749ae0abbe8d5210f06d97405d/box2d_py-2.3.8-cp37-cp37m-manylinux1_x86_64.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 33.9MB/s \n",
            "\u001b[?25hCollecting EasyProcess\n",
            "  Downloading https://files.pythonhosted.org/packages/48/3c/75573613641c90c6d094059ac28adb748560d99bd27ee6f80cce398f404e/EasyProcess-0.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1) (3.7.4.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.15,>=1.4.0->gym[box2d]==0.18.3) (0.16.0)\n",
            "Building wheels for collected packages: gym\n",
            "  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.18.3-cp37-none-any.whl size=1657529 sha256=b47b0898767c632118e5ed2312eecc68e0b877acd9bc26c1a52f601c85e1eb19\n",
            "  Stored in directory: /root/.cache/pip/wheels/93/c2/4c/2b4c9b85119994837c08315c9415d71008325b7004d385b418\n",
            "Successfully built gym\n",
            "\u001b[31mERROR: torchvision 0.10.0+cu102 has requirement torch==1.9.0, but you'll have torch 1.8.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: torchtext 0.10.0 has requirement torch==1.9.0, but you'll have torch 1.8.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: box2d-py, gym, EasyProcess, pyvirtualdisplay, torch\n",
            "  Found existing installation: gym 0.17.3\n",
            "    Uninstalling gym-0.17.3:\n",
            "      Successfully uninstalled gym-0.17.3\n",
            "  Found existing installation: torch 1.9.0+cu102\n",
            "    Uninstalling torch-1.9.0+cu102:\n",
            "      Successfully uninstalled torch-1.9.0+cu102\n",
            "Successfully installed EasyProcess-0.3 box2d-py-2.3.8 gym-0.18.3 pyvirtualdisplay-2.2 torch-1.8.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_-i3cdoYsks"
      },
      "source": [
        "接下來，設置好 virtual display，並引入所有必要的套件。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nl2nREINDLiw"
      },
      "source": [
        "%%capture\n",
        "from pyvirtualdisplay import Display\n",
        "virtual_display = Display(visible=0, size=(1400, 900))\n",
        "virtual_display.start()\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from IPython import display\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.distributions import Categorical\n",
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVu9-Vdrl4E3"
      },
      "source": [
        "# 請不要更改 random seed !!!!\n",
        "# 不然在judgeboi上 你的成績不會被reproduce !!!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fV9i8i2YkRbO"
      },
      "source": [
        "seed = 543 # Do not change this\n",
        "def fix(env, seed):\n",
        "  env.seed(seed)\n",
        "  env.action_space.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed(seed)\n",
        "  torch.cuda.manual_seed_all(seed)\n",
        "  np.random.seed(seed)\n",
        "  random.seed(seed)\n",
        "  #torch.set_deterministic(True)\n",
        "  #torch.use_deterministic_algorithms(True)\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "  torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "He0XDx6bzjgC"
      },
      "source": [
        "最後，引入 OpenAI 的 gym，並建立一個 [Lunar Lander](https://gym.openai.com/envs/LunarLander-v2/) 環境。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_4-xJcbBt09"
      },
      "source": [
        "%%capture\n",
        "import gym\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "env = gym.make('LunarLander-v2')\n",
        "\n",
        "fix(env, seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmiAOfqRwRX5"
      },
      "source": [
        "import time\n",
        "start = time.time()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcMjEUWTBEEB",
        "outputId": "e94fe910-e230-4a38-dbd8-68bd293d85fa"
      },
      "source": [
        "!pip freeze"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "absl-py==0.12.0\n",
            "alabaster==0.7.12\n",
            "albumentations==0.1.12\n",
            "altair==4.1.0\n",
            "appdirs==1.4.4\n",
            "argon2-cffi==20.1.0\n",
            "arviz==0.11.2\n",
            "astor==0.8.1\n",
            "astropy==4.2.1\n",
            "astunparse==1.6.3\n",
            "async-generator==1.10\n",
            "atari-py==0.2.9\n",
            "atomicwrites==1.4.0\n",
            "attrs==21.2.0\n",
            "audioread==2.1.9\n",
            "autograd==1.3\n",
            "Babel==2.9.1\n",
            "backcall==0.2.0\n",
            "beautifulsoup4==4.6.3\n",
            "bleach==3.3.0\n",
            "blis==0.4.1\n",
            "bokeh==2.3.2\n",
            "Bottleneck==1.3.2\n",
            "box2d-py==2.3.8\n",
            "branca==0.4.2\n",
            "bs4==0.0.1\n",
            "CacheControl==0.12.6\n",
            "cached-property==1.5.2\n",
            "cachetools==4.2.2\n",
            "catalogue==1.0.0\n",
            "certifi==2021.5.30\n",
            "cffi==1.14.5\n",
            "cftime==1.5.0\n",
            "chardet==3.0.4\n",
            "click==7.1.2\n",
            "cloudpickle==1.3.0\n",
            "cmake==3.12.0\n",
            "cmdstanpy==0.9.5\n",
            "colorcet==2.0.6\n",
            "colorlover==0.3.0\n",
            "community==1.0.0b1\n",
            "contextlib2==0.5.5\n",
            "convertdate==2.3.2\n",
            "coverage==3.7.1\n",
            "coveralls==0.5\n",
            "crcmod==1.7\n",
            "cufflinks==0.17.3\n",
            "cupy-cuda101==9.1.0\n",
            "cvxopt==1.2.6\n",
            "cvxpy==1.0.31\n",
            "cycler==0.10.0\n",
            "cymem==2.0.5\n",
            "Cython==0.29.23\n",
            "daft==0.0.4\n",
            "dask==2.12.0\n",
            "datascience==0.10.6\n",
            "debugpy==1.0.0\n",
            "decorator==4.4.2\n",
            "defusedxml==0.7.1\n",
            "descartes==1.1.0\n",
            "dill==0.3.4\n",
            "distributed==1.25.3\n",
            "dlib==19.18.0\n",
            "dm-tree==0.1.6\n",
            "docopt==0.6.2\n",
            "docutils==0.17.1\n",
            "dopamine-rl==1.0.5\n",
            "earthengine-api==0.1.269\n",
            "easydict==1.9\n",
            "EasyProcess==0.3\n",
            "ecos==2.0.7.post1\n",
            "editdistance==0.5.3\n",
            "en-core-web-sm==2.2.5\n",
            "entrypoints==0.3\n",
            "ephem==4.0.0.2\n",
            "et-xmlfile==1.1.0\n",
            "fa2==0.3.5\n",
            "fastai==1.0.61\n",
            "fastdtw==0.3.4\n",
            "fastprogress==1.0.0\n",
            "fastrlock==0.6\n",
            "fbprophet==0.7.1\n",
            "feather-format==0.4.1\n",
            "filelock==3.0.12\n",
            "firebase-admin==4.4.0\n",
            "fix-yahoo-finance==0.0.22\n",
            "Flask==1.1.4\n",
            "flatbuffers==1.12\n",
            "folium==0.8.3\n",
            "future==0.16.0\n",
            "gast==0.4.0\n",
            "GDAL==2.2.2\n",
            "gdown==3.6.4\n",
            "gensim==3.6.0\n",
            "geographiclib==1.50\n",
            "geopy==1.17.0\n",
            "gin-config==0.4.0\n",
            "glob2==0.7\n",
            "google==2.0.3\n",
            "google-api-core==1.26.3\n",
            "google-api-python-client==1.12.8\n",
            "google-auth==1.31.0\n",
            "google-auth-httplib2==0.0.4\n",
            "google-auth-oauthlib==0.4.4\n",
            "google-cloud-bigquery==1.21.0\n",
            "google-cloud-bigquery-storage==1.1.0\n",
            "google-cloud-core==1.0.3\n",
            "google-cloud-datastore==1.8.0\n",
            "google-cloud-firestore==1.7.0\n",
            "google-cloud-language==1.2.0\n",
            "google-cloud-storage==1.18.1\n",
            "google-cloud-translate==1.5.0\n",
            "google-colab==1.0.0\n",
            "google-pasta==0.2.0\n",
            "google-resumable-media==0.4.1\n",
            "googleapis-common-protos==1.53.0\n",
            "googledrivedownloader==0.4\n",
            "graphviz==0.10.1\n",
            "greenlet==1.1.0\n",
            "grpcio==1.34.1\n",
            "gspread==3.0.1\n",
            "gspread-dataframe==3.0.8\n",
            "gym==0.18.3\n",
            "h5py==3.1.0\n",
            "HeapDict==1.0.1\n",
            "hijri-converter==2.1.2\n",
            "holidays==0.10.5.2\n",
            "holoviews==1.14.4\n",
            "html5lib==1.0.1\n",
            "httpimport==0.5.18\n",
            "httplib2==0.17.4\n",
            "httplib2shim==0.0.3\n",
            "humanize==0.5.1\n",
            "hyperopt==0.1.2\n",
            "ideep4py==2.0.0.post3\n",
            "idna==2.10\n",
            "imageio==2.4.1\n",
            "imagesize==1.2.0\n",
            "imbalanced-learn==0.4.3\n",
            "imblearn==0.0\n",
            "imgaug==0.2.9\n",
            "importlib-metadata==4.5.0\n",
            "importlib-resources==5.1.4\n",
            "imutils==0.5.4\n",
            "inflect==2.1.0\n",
            "iniconfig==1.1.1\n",
            "install==1.3.4\n",
            "intel-openmp==2021.2.0\n",
            "intervaltree==2.1.0\n",
            "ipykernel==4.10.1\n",
            "ipython==5.5.0\n",
            "ipython-genutils==0.2.0\n",
            "ipython-sql==0.3.9\n",
            "ipywidgets==7.6.3\n",
            "itsdangerous==1.1.0\n",
            "jax==0.2.13\n",
            "jaxlib==0.1.66+cuda110\n",
            "jdcal==1.4.1\n",
            "jedi==0.18.0\n",
            "jieba==0.42.1\n",
            "Jinja2==2.11.3\n",
            "joblib==1.0.1\n",
            "jpeg4py==0.1.4\n",
            "jsonschema==2.6.0\n",
            "jupyter==1.0.0\n",
            "jupyter-client==5.3.5\n",
            "jupyter-console==5.2.0\n",
            "jupyter-core==4.7.1\n",
            "jupyterlab-pygments==0.1.2\n",
            "jupyterlab-widgets==1.0.0\n",
            "kaggle==1.5.12\n",
            "kapre==0.3.5\n",
            "Keras==2.4.3\n",
            "keras-nightly==2.5.0.dev2021032900\n",
            "Keras-Preprocessing==1.1.2\n",
            "keras-vis==0.4.1\n",
            "kiwisolver==1.3.1\n",
            "korean-lunar-calendar==0.2.1\n",
            "librosa==0.8.1\n",
            "lightgbm==2.2.3\n",
            "llvmlite==0.34.0\n",
            "lmdb==0.99\n",
            "LunarCalendar==0.0.9\n",
            "lxml==4.2.6\n",
            "Markdown==3.3.4\n",
            "MarkupSafe==2.0.1\n",
            "matplotlib==3.2.2\n",
            "matplotlib-inline==0.1.2\n",
            "matplotlib-venn==0.11.6\n",
            "missingno==0.4.2\n",
            "mistune==0.8.4\n",
            "mizani==0.6.0\n",
            "mkl==2019.0\n",
            "mlxtend==0.14.0\n",
            "more-itertools==8.8.0\n",
            "moviepy==0.2.3.5\n",
            "mpmath==1.2.1\n",
            "msgpack==1.0.2\n",
            "multiprocess==0.70.12.2\n",
            "multitasking==0.0.9\n",
            "murmurhash==1.0.5\n",
            "music21==5.5.0\n",
            "natsort==5.5.0\n",
            "nbclient==0.5.3\n",
            "nbconvert==5.6.1\n",
            "nbformat==5.1.3\n",
            "nest-asyncio==1.5.1\n",
            "netCDF4==1.5.6\n",
            "networkx==2.5.1\n",
            "nibabel==3.0.2\n",
            "nltk==3.2.5\n",
            "notebook==5.3.1\n",
            "numba==0.51.2\n",
            "numexpr==2.7.3\n",
            "numpy==1.19.5\n",
            "nvidia-ml-py3==7.352.0\n",
            "oauth2client==4.1.3\n",
            "oauthlib==3.1.1\n",
            "okgrade==0.4.3\n",
            "opencv-contrib-python==4.1.2.30\n",
            "opencv-python==4.1.2.30\n",
            "openpyxl==2.5.9\n",
            "opt-einsum==3.3.0\n",
            "osqp==0.6.2.post0\n",
            "packaging==20.9\n",
            "palettable==3.3.0\n",
            "pandas==1.1.5\n",
            "pandas-datareader==0.9.0\n",
            "pandas-gbq==0.13.3\n",
            "pandas-profiling==1.4.1\n",
            "pandocfilters==1.4.3\n",
            "panel==0.11.3\n",
            "param==1.10.1\n",
            "parso==0.8.2\n",
            "pathlib==1.0.1\n",
            "patsy==0.5.1\n",
            "pexpect==4.8.0\n",
            "pickleshare==0.7.5\n",
            "Pillow==7.1.2\n",
            "pip-tools==4.5.1\n",
            "plac==1.1.3\n",
            "plotly==4.4.1\n",
            "plotnine==0.6.0\n",
            "pluggy==0.7.1\n",
            "pooch==1.4.0\n",
            "portpicker==1.3.9\n",
            "prefetch-generator==1.0.1\n",
            "preshed==3.0.5\n",
            "prettytable==2.1.0\n",
            "progressbar2==3.38.0\n",
            "prometheus-client==0.11.0\n",
            "promise==2.3\n",
            "prompt-toolkit==1.0.18\n",
            "protobuf==3.12.4\n",
            "psutil==5.4.8\n",
            "psycopg2==2.7.6.1\n",
            "ptyprocess==0.7.0\n",
            "py==1.10.0\n",
            "pyarrow==3.0.0\n",
            "pyasn1==0.4.8\n",
            "pyasn1-modules==0.2.8\n",
            "pycocotools==2.0.2\n",
            "pycparser==2.20\n",
            "pyct==0.4.8\n",
            "pydata-google-auth==1.2.0\n",
            "pydot==1.3.0\n",
            "pydot-ng==2.0.0\n",
            "pydotplus==2.0.2\n",
            "PyDrive==1.3.1\n",
            "pyemd==0.5.1\n",
            "pyerfa==2.0.0\n",
            "pyglet==1.5.0\n",
            "Pygments==2.6.1\n",
            "pygobject==3.26.1\n",
            "pymc3==3.11.2\n",
            "PyMeeus==0.5.11\n",
            "pymongo==3.11.4\n",
            "pymystem3==0.2.0\n",
            "PyOpenGL==3.1.5\n",
            "pyparsing==2.4.7\n",
            "pyrsistent==0.17.3\n",
            "pysndfile==1.3.8\n",
            "PySocks==1.7.1\n",
            "pystan==2.19.1.1\n",
            "pytest==3.6.4\n",
            "python-apt==0.0.0\n",
            "python-chess==0.23.11\n",
            "python-dateutil==2.8.1\n",
            "python-louvain==0.15\n",
            "python-slugify==5.0.2\n",
            "python-utils==2.5.6\n",
            "pytz==2018.9\n",
            "PyVirtualDisplay==2.2\n",
            "pyviz-comms==2.0.2\n",
            "PyWavelets==1.1.1\n",
            "PyYAML==3.13\n",
            "pyzmq==22.1.0\n",
            "qdldl==0.1.5.post0\n",
            "qtconsole==5.1.0\n",
            "QtPy==1.9.0\n",
            "regex==2019.12.20\n",
            "requests==2.23.0\n",
            "requests-oauthlib==1.3.0\n",
            "resampy==0.2.2\n",
            "retrying==1.3.3\n",
            "rpy2==3.4.5\n",
            "rsa==4.7.2\n",
            "scikit-image==0.16.2\n",
            "scikit-learn==0.22.2.post1\n",
            "scipy==1.4.1\n",
            "screen-resolution-extra==0.0.0\n",
            "scs==2.1.4\n",
            "seaborn==0.11.1\n",
            "semver==2.13.0\n",
            "Send2Trash==1.5.0\n",
            "setuptools-git==1.2\n",
            "Shapely==1.7.1\n",
            "simplegeneric==0.8.1\n",
            "six==1.15.0\n",
            "sklearn==0.0\n",
            "sklearn-pandas==1.8.0\n",
            "smart-open==5.1.0\n",
            "snowballstemmer==2.1.0\n",
            "sortedcontainers==2.4.0\n",
            "SoundFile==0.10.3.post1\n",
            "spacy==2.2.4\n",
            "Sphinx==1.8.5\n",
            "sphinxcontrib-serializinghtml==1.1.5\n",
            "sphinxcontrib-websupport==1.2.4\n",
            "SQLAlchemy==1.4.18\n",
            "sqlparse==0.4.1\n",
            "srsly==1.0.5\n",
            "statsmodels==0.10.2\n",
            "sympy==1.7.1\n",
            "tables==3.4.4\n",
            "tabulate==0.8.9\n",
            "tblib==1.7.0\n",
            "tensorboard==2.5.0\n",
            "tensorboard-data-server==0.6.1\n",
            "tensorboard-plugin-wit==1.8.0\n",
            "tensorflow==2.5.0\n",
            "tensorflow-datasets==4.0.1\n",
            "tensorflow-estimator==2.5.0\n",
            "tensorflow-gcs-config==2.5.0\n",
            "tensorflow-hub==0.12.0\n",
            "tensorflow-metadata==1.0.0\n",
            "tensorflow-probability==0.12.1\n",
            "termcolor==1.1.0\n",
            "terminado==0.10.1\n",
            "testpath==0.5.0\n",
            "text-unidecode==1.3\n",
            "textblob==0.15.3\n",
            "Theano-PyMC==1.1.2\n",
            "thinc==7.4.0\n",
            "tifffile==2021.6.14\n",
            "toml==0.10.2\n",
            "toolz==0.11.1\n",
            "torch==1.8.1\n",
            "torchsummary==1.5.1\n",
            "torchtext==0.10.0\n",
            "torchvision==0.10.0+cu102\n",
            "tornado==5.1.1\n",
            "tqdm==4.41.1\n",
            "traitlets==5.0.5\n",
            "tweepy==3.10.0\n",
            "typeguard==2.7.1\n",
            "typing-extensions==3.7.4.3\n",
            "tzlocal==1.5.1\n",
            "uritemplate==3.0.1\n",
            "urllib3==1.24.3\n",
            "vega-datasets==0.9.0\n",
            "wasabi==0.8.2\n",
            "wcwidth==0.2.5\n",
            "webencodings==0.5.1\n",
            "Werkzeug==1.0.1\n",
            "widgetsnbextension==3.5.1\n",
            "wordcloud==1.5.0\n",
            "wrapt==1.12.1\n",
            "xarray==0.18.2\n",
            "xgboost==0.90\n",
            "xkit==0.0.0\n",
            "xlrd==1.1.0\n",
            "xlwt==1.3.0\n",
            "yellowbrick==0.9.1\n",
            "zict==2.0.0\n",
            "zipp==3.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrkVvTrvWZ5H"
      },
      "source": [
        "## 什麼是 Lunar Lander？\n",
        "\n",
        "“LunarLander-v2” 這個環境是在模擬登月小艇降落在月球表面時的情形。\n",
        "這個任務的目標是讓登月小艇「安全地」降落在兩個黃色旗幟間的平地上。\n",
        "> Landing pad is always at coordinates (0,0).\n",
        "> Coordinates are the first two numbers in state vector.\n",
        "\n",
        "![](https://gym.openai.com/assets/docs/aeloop-138c89d44114492fd02822303e6b4b07213010bb14ca5856d2d49d6b62d88e53.svg)\n",
        "\n",
        "所謂的「環境」其實同時包括了 agent 和 environment。\n",
        "我們利用 `step()` 這個函式讓 agent 行動，而後函式便會回傳 environment 給予的 observation/state（以下這兩個名詞代表同樣的意思）和 reward。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIbp82sljvAt"
      },
      "source": [
        "### Observation / State\n",
        "\n",
        "首先，我們可以看看 environment 回傳給 agent 的 observation 究竟是長什麼樣子的資料："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsXZra3N9R5T",
        "outputId": "ef3b4399-a787-442e-8b5a-808c46bf53d0"
      },
      "source": [
        "print(env.observation_space)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Box(-inf, inf, (8,), float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezdfoThbAQ49"
      },
      "source": [
        "`Box(8,)` 說明我們會拿到 8 維的向量作為 observation，其中包含：垂直及水平座標、速度、角度、加速度等等，這部分我們就不細說。\n",
        "\n",
        "### Action\n",
        "\n",
        "而在 agent 得到 observation 和 reward 以後，能夠採取的動作有："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1k4dIrBAaKi",
        "outputId": "4c664e6f-6ee5-4929-cfee-3a55b98d9bc2"
      },
      "source": [
        "print(env.action_space)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Discrete(4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dejXT6PHBrPn"
      },
      "source": [
        "`Discrete(4)` 說明 agent 可以採取四種離散的行動：\n",
        "- 0 代表不採取任何行動\n",
        "- 2 代表主引擎向下噴射\n",
        "- 1, 3 則是向左右噴射\n",
        "\n",
        "接下來，我們嘗試讓 agent 與 environment 互動。\n",
        "在進行任何操作前，建議先呼叫 `reset()` 函式讓整個「環境」重置。\n",
        "而這個函式同時會回傳「環境」最初始的狀態。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pi4OmrmZgnWA",
        "outputId": "a7016361-f4c3-4293-a1ec-66c140749c3b"
      },
      "source": [
        "initial_state = env.reset()\n",
        "print(initial_state)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0.00396109  1.4083536   0.40119505 -0.11407257 -0.00458307 -0.09087662\n",
            "  0.          0.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBx0mEqqgxJ9"
      },
      "source": [
        "接著，我們試著從 agent 的四種行動空間中，隨機採取一個行動"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxkOEXRKgizt",
        "outputId": "2d4877a7-4e74-4978-da93-1375453ac217"
      },
      "source": [
        "random_action = env.action_space.sample()\n",
        "print(random_action)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mns-bO01g0-J"
      },
      "source": [
        "再利用 `step()` 函式讓 agent 根據我們隨機抽樣出來的 `random_action` 動作。\n",
        "而這個函式會回傳四項資訊：\n",
        "- observation / state\n",
        "- reward\n",
        "- 完成與否\n",
        "- 其餘資訊"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_WViSxGgIk9"
      },
      "source": [
        "observation, reward, done, info = env.step(random_action)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdieGq7NuBIm"
      },
      "source": [
        "第一項資訊 `observation` 即為 agent 採取行動之後，agent 對於環境的 observation 或者說環境的 state 為何。\n",
        "而第三項資訊 `done` 則是 `True` 或 `False` 的布林值，當登月小艇成功著陸或是不幸墜毀時，代表這個回合（episode）也就跟著結束了，此時 `step()` 函式便會回傳 `done = True`，而在那之前，`done` 則保持 `False`。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yK7r126kuCNp",
        "outputId": "bedf8db9-401b-4697-ddf5-90e4f5511a89"
      },
      "source": [
        "print(done)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKdS8vOihxhc"
      },
      "source": [
        "### Reward\n",
        "\n",
        "而「環境」給予的 reward 大致是這樣計算：\n",
        "- 小艇墜毀得到 -100 分\n",
        "- 小艇在黃旗幟之間成功著地則得 100~140 分\n",
        "- 噴射主引擎（向下噴火）每次 -0.3 分\n",
        "- 小艇最終完全靜止則再得 100 分\n",
        "- 小艇每隻腳碰觸地面 +10 分\n",
        "\n",
        "> Reward for moving from the top of the screen to landing pad and zero speed is about 100..140 points.\n",
        "> If lander moves away from landing pad it loses reward back.\n",
        "> Episode finishes if the lander crashes or comes to rest, receiving additional -100 or +100 points.\n",
        "> Each leg ground contact is +10.\n",
        "> Firing main engine is -0.3 points each frame.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxQNs77hi0_7",
        "outputId": "49db167e-721a-49c8-dec6-91180907346d"
      },
      "source": [
        "print(reward) # after doing a random action (0), the immediate reward is stored in this"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-0.8588900517154912\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mhqp6D-XgHpe"
      },
      "source": [
        "### Random Agent\n",
        "\n",
        "最後，在進入實做之前，我們就來看看這樣一個 random agent 能否成功登陸月球："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "Y3G0bxoccelv",
        "outputId": "e6a323ef-ce45-4749-ef9d-01d100649d34"
      },
      "source": [
        "\n",
        "env.reset()\n",
        "\n",
        "img = plt.imshow(env.render(mode='rgb_array'))\n",
        "\n",
        "done = False\n",
        "while not done:\n",
        "    action = env.action_space.sample()\n",
        "    observation, reward, done, _ = env.step(action)\n",
        "\n",
        "    img.set_data(env.render(mode='rgb_array'))\n",
        "    display.display(plt.gcf())\n",
        "    display.clear_output(wait=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5paWqo7tWL2"
      },
      "source": [
        "## Policy Gradient\n",
        "\n",
        "現在來搭建一個簡單的 policy network。\n",
        "我們預設模型的輸入是 8-dim 的 observation，輸出則是離散的四個動作之一："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8tdmeD-tZew"
      },
      "source": [
        "class PolicyGradientNetwork(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(8, 16)\n",
        "        self.fc2 = nn.Linear(16, 16)\n",
        "        self.fc3 = nn.Linear(16, 4)\n",
        "\n",
        "    def forward(self, state):\n",
        "        hid = torch.tanh(self.fc1(state))\n",
        "        hid = torch.tanh(self.fc2(hid))\n",
        "        return F.softmax(self.fc3(hid), dim=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhfHAGaSg2eC"
      },
      "source": [
        "Qnet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jes6qS13g1ok"
      },
      "source": [
        "class QNetwork(nn.Module):\n",
        "    \"\"\"Actor (Policy) Model.\"\"\"\n",
        "\n",
        "    def __init__(self, state_size, action_size, seed):\n",
        "        \"\"\"Initialize parameters and build model.\n",
        "        Params\n",
        "        ======\n",
        "            state_size (int): Dimension of each state\n",
        "            action_size (int): Dimension of each action\n",
        "            seed (int): Random seed\n",
        "        \"\"\"\n",
        "        super(QNetwork, self).__init__()\n",
        "        self.seed = torch.manual_seed(seed)\n",
        "\n",
        "        hidden_layer=32\n",
        "        self.conv1 = nn.Linear(state_size, 16)\n",
        "        self.bn1 = nn.BatchNorm1d(16)\n",
        "        self.conv2 = nn.Linear(16, hidden_layer)\n",
        "        self.bn2 = nn.BatchNorm1d(hidden_layer)\n",
        "        self.conv3 = nn.Linear(hidden_layer, hidden_layer)\n",
        "        self.bn3 = nn.BatchNorm1d(hidden_layer)\n",
        "\n",
        "        self.head = nn.Linear(hidden_layer, action_size)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Build a network that maps state -> action values.\"\"\"\n",
        "\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        #A1 = F.relu(self.fc1(state))\n",
        "        #action_pros = F.softmax(self.fc2(A1),dim=1)\n",
        "\n",
        "        return self.head(x.view(x.size(0), -1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynbqJrhIFTC3"
      },
      "source": [
        "再來，搭建一個簡單的 agent，並搭配上方的 policy network 來採取行動。\n",
        "這個 agent 能做到以下幾件事：\n",
        "- `learn()`：從記下來的 log probabilities 及 rewards 來更新 policy network。\n",
        "- `sample()`：從 environment 得到 observation 之後，利用 policy network 得出應該採取的行動。\n",
        "而此函式除了回傳抽樣出來的 action，也會回傳此次抽樣的 log probabilities。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4kFhIyzhVtt"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "from collections import namedtuple, deque\n",
        "\n",
        "BUFFER_SIZE = int(1e5)  # replay buffer size\n",
        "BATCH_SIZE = 64  # minibatch size\n",
        "GAMMA = 0.99  # discount factor\n",
        "TAU = 1e-3  # for soft update of target parameters\n",
        "LR = 5e-3  # learning rate\n",
        "UPDATE_EVERY = 4  # how often to update the network\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "class Agent():\n",
        "    \"\"\"Interacts with and learns from the environment.\"\"\"\n",
        "\n",
        "    def __init__(self, state_size, action_size, seed):\n",
        "        \"\"\"Initialize an Agent object.\n",
        "\n",
        "        Params\n",
        "        ======\n",
        "            state_size (int): dimension of each state\n",
        "            action_size (int): dimension of each action\n",
        "            seed (int): random seed\n",
        "        \"\"\"\n",
        "        self.state_size = state_size\n",
        "        self.action_size = action_size\n",
        "        self.seed = random.seed(seed)\n",
        "\n",
        "        # Q-Network\n",
        "        self.qnetwork_local = QNetwork(state_size, action_size, seed).to(device)\n",
        "        self.qnetwork_target = QNetwork(state_size, action_size, seed).to(device)\n",
        "        self.optimizer = optim.Adam(self.qnetwork_local.parameters(), lr=LR)\n",
        "\n",
        "        # Replay memory\n",
        "        self.memory = ReplayBuffer(action_size, BUFFER_SIZE, BATCH_SIZE, seed)\n",
        "        # Initialize time step (for updating every UPDATE_EVERY steps)\n",
        "        self.t_step = 0\n",
        "\n",
        "    def step(self, state, action, reward, next_state, done):\n",
        "        # Save experience in replay memory\n",
        "        self.memory.add(state, action, reward, next_state, done)\n",
        "\n",
        "        # Learn every UPDATE_EVERY time steps.\n",
        "        self.t_step = (self.t_step + 1) % UPDATE_EVERY\n",
        "        if self.t_step == 0:\n",
        "            # If enough samples are available in memory, get random subset and learn\n",
        "            if len(self.memory) > BATCH_SIZE:\n",
        "                experiences = self.memory.sample()\n",
        "                self.learn(experiences, GAMMA)\n",
        "\n",
        "    def act(self, state, eps=0.):\n",
        "        \"\"\"Returns actions for given state as per current policy.\n",
        "\n",
        "        Params\n",
        "        ======\n",
        "            state (array_like): current state\n",
        "            eps (float): epsilon, for epsilon-greedy action selection\n",
        "        \"\"\"\n",
        "        state = torch.from_numpy(state).float().unsqueeze(0).to(device)\n",
        "        self.qnetwork_local.eval()\n",
        "        with torch.no_grad():\n",
        "            action_values = self.qnetwork_local(state)\n",
        "        self.qnetwork_local.train()\n",
        "\n",
        "        # Epsilon-greedy action selection\n",
        "        if random.random() > eps:\n",
        "            return np.argmax(action_values.cpu().data.numpy())\n",
        "        else:\n",
        "            return random.choice(np.arange(self.action_size))\n",
        "\n",
        "    def learn(self, experiences, gamma):\n",
        "        \"\"\"Update value parameters using given batch of experience tuples.\n",
        "\n",
        "        Params\n",
        "        ======\n",
        "            experiences (Tuple[torch.Tensor]): tuple of (s, a, r, s', done) tuples\n",
        "            gamma (float): discount factor\n",
        "        \"\"\"\n",
        "        states, actions, rewards, next_states, dones = experiences\n",
        "\n",
        "        # TODO: compute and minimize the loss\n",
        "        \"*** YOUR CODE HERE ***\"\n",
        "\n",
        "        q_hat = self.qnetwork_target.forward(next_states).detach().max(dim=1)[0].unsqueeze(1)\n",
        "        target = rewards + gamma * q_hat * (1 - dones)\n",
        "        q_local = self.qnetwork_local.forward(states).gather(1, actions)\n",
        "        loss = F.mse_loss(q_local, target)\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "        # ------------------- update target network ------------------- #\n",
        "        self.soft_update(self.qnetwork_local, self.qnetwork_target, TAU)\n",
        "\n",
        "    def soft_update(self, local_model, target_model, tau):  # update the target model\n",
        "        \"\"\"Soft update model parameters.\n",
        "        θ_target = τ*θ_local + (1 - τ)*θ_target\n",
        "\n",
        "        Params\n",
        "        ======\n",
        "            local_model (PyTorch model): weights will be copied from\n",
        "            target_model (PyTorch model): weights will be copied to\n",
        "            tau (float): interpolation parameter\n",
        "        \"\"\"\n",
        "        for target_param, local_param in zip(target_model.parameters(), local_model.parameters()):\n",
        "            target_param.data.copy_(tau * local_param.data + (1.0 - tau) * target_param.data)\n",
        "\n",
        "\n",
        "class ReplayBuffer:\n",
        "    \"\"\"Fixed-size buffer to store experience tuples.\"\"\"\n",
        "\n",
        "    def __init__(self, action_size, buffer_size, batch_size, seed):\n",
        "        \"\"\"Initialize a ReplayBuffer object.\n",
        "\n",
        "        Params\n",
        "        ======\n",
        "            action_size (int): dimension of each action\n",
        "            buffer_size (int): maximum size of buffer\n",
        "            batch_size (int): size of each training batch\n",
        "            seed (int): random seed\n",
        "        \"\"\"\n",
        "        self.action_size = action_size\n",
        "        self.memory = deque(maxlen=buffer_size)\n",
        "        self.batch_size = batch_size\n",
        "        self.experience = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
        "        self.seed = random.seed(seed)\n",
        "\n",
        "    def add(self, state, action, reward, next_state, done):\n",
        "        \"\"\"Add a new experience to memory.\"\"\"\n",
        "        e = self.experience(state, action, reward, next_state, done)\n",
        "        self.memory.append(e)\n",
        "\n",
        "    def sample(self):\n",
        "        \"\"\"Randomly sample a batch of experiences from memory.\"\"\"\n",
        "        experiences = random.sample(self.memory, k=self.batch_size)\n",
        "\n",
        "        states = torch.from_numpy(np.vstack([e.state for e in experiences if e is not None])).float().to(device)\n",
        "        actions = torch.from_numpy(np.vstack([e.action for e in experiences if e is not None])).long().to(device)\n",
        "        rewards = torch.from_numpy(np.vstack([e.reward for e in experiences if e is not None])).float().to(device)\n",
        "        next_states = torch.from_numpy(np.vstack([e.next_state for e in experiences if e is not None])).float().to(\n",
        "            device)\n",
        "        dones = torch.from_numpy(np.vstack([e.done for e in experiences if e is not None]).astype(np.uint8)).float().to(\n",
        "            device)\n",
        "\n",
        "        return (states, actions, rewards, next_states, dones)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Return the current size of internal memory.\"\"\"\n",
        "        return len(self.memory)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZo-IxJx286z"
      },
      "source": [
        "\n",
        "class PolicyGradientAgent():\n",
        "\n",
        "    def __init__(self, network):\n",
        "        self.network = network\n",
        "        self.optimizer = optim.SGD(self.network.parameters(), lr=0.001)\n",
        "\n",
        "    def forward(self, state):\n",
        "        return self.network(state)\n",
        "    def learn(self, log_probs, rewards):\n",
        "        loss = (-log_probs * rewards).sum() # You don't need to revise this to pass simple baseline (but you can)\n",
        "\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "    def sample(self, state):\n",
        "        action_prob = self.network(torch.FloatTensor(state))\n",
        "        action_dist = Categorical(action_prob)\n",
        "        action = action_dist.sample()\n",
        "        log_prob = action_dist.log_prob(action)\n",
        "        return action.item(), log_prob\n",
        "\n",
        "    def save(self, PATH): # You should not revise this\n",
        "        Agent_Dict = {\n",
        "            \"network\" : self.network.state_dict(),\n",
        "            \"optimizer\" : self.optimizer.state_dict()\n",
        "        }\n",
        "        torch.save(Agent_Dict, PATH)\n",
        "\n",
        "    def load(self, PATH): # You should not revise this\n",
        "        checkpoint = torch.load(PATH)\n",
        "        self.network.load_state_dict(checkpoint[\"network\"])\n",
        "        #如果要儲存過程或是中斷訓練後想繼續可以用喔 ^_^\n",
        "        self.optimizer.load_state_dict(checkpoint[\"optimizer\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auIWEbrw5cip",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fbf4280-3c9b-4168-941a-810b3b105deb"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Jun 20 14:26:46 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P8     9W /  70W |      3MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehPlnTKyRZf9"
      },
      "source": [
        "最後，建立一個 network 和 agent，就可以開始進行訓練了。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfJIvML-RYjL"
      },
      "source": [
        "network = PolicyGradientNetwork()\n",
        "agent = PolicyGradientAgent(network)\n",
        "#agent = PolicyGradientAgent()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wgDmx6SkXIz"
      },
      "source": [
        "#env = gym.make('LunarLander-v2')\n",
        "#fix(env, seed)\n",
        "agent = Agent(state_size=8, action_size=4, seed=seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouv23glgf5Qt"
      },
      "source": [
        "## 訓練 Agent\n",
        "\n",
        "現在我們開始訓練 agent。\n",
        "透過讓 agent 和 environment 互動，我們記住每一組對應的 log probabilities 及 reward，並在成功登陸或者不幸墜毀後，回放這些「記憶」來訓練 policy network。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "id": "MI55xtngiysk",
        "outputId": "baee5bc2-862d-4a7b-f475-25d43de23d74"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "env = gym.make('LunarLander-v2')\n",
        "env.seed(543)\n",
        "\n",
        "agent = Agent(state_size=8, action_size=4, seed=543)\n",
        "def dqn(n_episodes=2000, max_t=1000, eps_start=1.0, eps_end=0.01, eps_decay=0.995):\n",
        "    \"\"\"Deep Q-Learning.\n",
        "\n",
        "    Params\n",
        "    ======\n",
        "        n_episodes (int): maximum number of training episodes\n",
        "        max_t (int): maximum number of timesteps per episode\n",
        "        eps_start (float): starting value of epsilon, for epsilon-greedy action selection\n",
        "        eps_end (float): minimum value of epsilon\n",
        "        eps_decay (float): multiplicative factor (per episode) for decreasing epsilon\n",
        "    \"\"\"\n",
        "    scores = []  # list containing scores from each episode\n",
        "    scores_window = deque(maxlen=100)  # last 100 scores\n",
        "    eps = eps_start  # initialize epsilon\n",
        "    for i_episode in range(1, n_episodes + 1):\n",
        "        state = env.reset()\n",
        "        score = 0\n",
        "        for t in range(max_t):\n",
        "            action = agent.act(state, eps)\n",
        "            next_state, reward, done, _ = env.step(action)\n",
        "            agent.step(state, action, reward, next_state, done)  # update QNetwork\n",
        "            state = next_state\n",
        "            score += reward\n",
        "            if done:\n",
        "                break\n",
        "        scores_window.append(score)  # save most recent score\n",
        "        scores.append(score)  # save most recent score\n",
        "        eps = max(eps_end, eps_decay * eps)  # decrease epsilon\n",
        "        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)), end=\"\")\n",
        "        if i_episode % 100 == 0:\n",
        "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)))\n",
        "        if np.mean(scores_window) >= 241.0:\n",
        "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode - 100,\n",
        "                                                                                         np.mean(scores_window)))\n",
        "            torch.save(agent.qnetwork_local.state_dict(), 'checkpoint.pth')\n",
        "            break\n",
        "    return scores\n",
        "\n",
        "\n",
        "scores = dqn()\n",
        "\n",
        "# plot the scores\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "plt.plot(np.arange(len(scores)), scores)\n",
        "plt.ylabel('Score')\n",
        "plt.xlabel('Episode #')\n",
        "plt.show()\n",
        "\n",
        "agent.qnetwork_local.load_state_dict(torch.load('checkpoint.pth'))\n",
        "\n",
        "for i in range(3):\n",
        "    state = env.reset()\n",
        "    for j in range(2000):\n",
        "        action = agent.act(state)\n",
        "        env.render()\n",
        "        state, reward, done, _ = env.step(action)\n",
        "        if done:\n",
        "            state = env.reset()\n",
        "\n",
        "env.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Episode 100\tAverage Score: -144.04\n",
            "Episode 200\tAverage Score: -138.16\n",
            "Episode 300\tAverage Score: -54.18\n",
            "Episode 400\tAverage Score: 11.04\n",
            "Episode 500\tAverage Score: 144.04\n",
            "Episode 600\tAverage Score: 184.15\n",
            "Episode 700\tAverage Score: 204.99\n",
            "Episode 800\tAverage Score: 213.32\n",
            "Episode 900\tAverage Score: 199.77\n",
            "Episode 1000\tAverage Score: 211.63\n",
            "Episode 1100\tAverage Score: 230.55\n",
            "Episode 1123\tAverage Score: 242.05\n",
            "Environment solved in 1023 episodes!\tAverage Score: 242.05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272,
          "referenced_widgets": [
            "a87f008708034826a08a55aa54c656e9",
            "929755c06eac4195afe8c016c921cc1a",
            "6098f7fafbbf450d9f0f8dc0960f26f6",
            "423062d6eb5a463b89dc1297cbdbe438",
            "84ed7764c8624281874c0e4b809c6bfc",
            "9d0ddab78ac842f199a9701f4f64b855",
            "d8400b6a99504006a6f08e2cc8c49299",
            "7a9d8a47b5914d29ac72972301049e44"
          ]
        },
        "id": "vg5rxBBaf38_",
        "outputId": "40088ab9-13da-4494-dae1-bac4df5e51f9"
      },
      "source": [
        "#agent.network.train()  # 訓練前，先確保 network 處在 training 模式\n",
        "EPISODE_PER_BATCH = 5  # 每蒐集 5 個 episodes 更新一次 agent\n",
        "NUM_BATCH = 1000        # 總共更新 400 次\n",
        "\n",
        "avg_total_rewards, avg_final_rewards = [], []\n",
        "\n",
        "prg_bar = tqdm(range(NUM_BATCH))\n",
        "for batch in prg_bar:\n",
        "\n",
        "    log_probs, rewards = [], []\n",
        "    total_rewards, final_rewards = [], []\n",
        "\n",
        "    # 蒐集訓練資料\n",
        "    for episode in range(EPISODE_PER_BATCH):\n",
        "\n",
        "        state = env.reset()\n",
        "        total_reward, total_step = 0, 0\n",
        "        seq_rewards = []\n",
        "        while True:\n",
        "\n",
        "            action, log_prob = agent.sample(state) # at , log(at|st)\n",
        "            next_state, reward, done, _ = env.step(action)\n",
        "\n",
        "            log_probs.append(log_prob) # [log(a1|s1), log(a2|s2), ...., log(at|st)]\n",
        "            #seq_rewards.append(reward)\n",
        "            state = next_state\n",
        "            total_reward += reward\n",
        "            rewards.append(reward) #改這裡\n",
        "            for x in range(total_step):\n",
        "              rewards[total_step-1-x] += reward*(0.95**(1+x))\n",
        "            total_step += 1\n",
        "\n",
        "\n",
        "\n",
        "            # ! 重要 ！\n",
        "            # 現在的reward 的implementation 為每個時刻的瞬時reward, 給定action_list : a1, a2, a3 ......\n",
        "            # reward :     r1, r2 ,r3 ......\n",
        "            # medium：將reward調整成accumulative decaying reward, 給定action_list : a1, a2,a3 ......\n",
        "            # reward :     r1+0.99*r2+0.99^2*r3+......, r2+0.99*r3+0.99^2*r4+...... ,r3+0.99*r4+0.99^2*r5+ ......\n",
        "            # boss : implement DQN\n",
        "            if done:\n",
        "                final_rewards.append(reward)\n",
        "                total_rewards.append(total_reward)\n",
        "                break\n",
        "\n",
        "    print(f\"rewards looks like \", np.shape(rewards))\n",
        "    print(rewards)\n",
        "    print(f\"log_probs looks like \", np.shape(log_probs))\n",
        "    # 紀錄訓練過程\n",
        "    avg_total_reward = sum(total_rewards) / len(total_rewards)\n",
        "    avg_final_reward = sum(final_rewards) / len(final_rewards)\n",
        "    avg_total_rewards.append(avg_total_reward)\n",
        "    avg_final_rewards.append(avg_final_reward)\n",
        "    prg_bar.set_description(f\"Total: {avg_total_reward: 4.1f}, Final: {avg_final_reward: 4.1f}\")\n",
        "\n",
        "    # 更新網路\n",
        "    # rewards = np.concatenate(rewards, axis=0)\n",
        "    rewards = (rewards - np.mean(rewards)) / (np.std(rewards) + 1e-9)  # 將 reward 正規標準化\n",
        "    agent.learn(torch.stack(log_probs), torch.from_numpy(rewards))\n",
        "    print(\"logs prob looks like \", torch.stack(log_probs).size())\n",
        "    print(\"torch.from_numpy(rewards) looks like \", torch.from_numpy(rewards).size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a87f008708034826a08a55aa54c656e9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-f580c79bfa23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# at , log(at|st)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Agent' object has no attribute 'sample'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNb_tuFYhKVK"
      },
      "source": [
        "### 訓練結果\n",
        "\n",
        "訓練過程中，我們持續記下了 `avg_total_reward`，這個數值代表的是：每次更新 policy network 前，我們讓 agent 玩數個回合（episodes），而這些回合的平均 total rewards 為何。\n",
        "理論上，若是 agent 一直在進步，則所得到的 `avg_total_reward` 也會持續上升，直至 250 上下。\n",
        "若將其畫出來則結果如下："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "wZYOI8H10SHN",
        "outputId": "2dcc1457-8731-43d5-f593-f61fc162925e"
      },
      "source": [
        "end = time.time()\n",
        "plt.plot(avg_total_rewards)\n",
        "plt.title(\"Total Rewards\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-a6fd66707434>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg_total_rewards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Total Rewards\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'avg_total_rewards' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mV5jj4dThz0Y"
      },
      "source": [
        "另外，`avg_final_reward` 代表的是多個回合的平均 final rewards，而 final reward 即是 agent 在單一回合中拿到的最後一個 reward。\n",
        "如果同學們還記得環境給予登月小艇 reward 的方式，便會知道，不論**回合的最後**小艇是不幸墜毀、飛出畫面、或是靜止在地面上，都會受到額外地獎勵或處罰。\n",
        "也因此，final reward 可被用來觀察 agent 的「著地」是否順利等資訊。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "txDZ5vlGWz5w",
        "outputId": "0ba00784-062f-4f11-d162-477f62ca05bb"
      },
      "source": [
        "plt.plot(avg_final_rewards)\n",
        "plt.title(\"Final Rewards\")\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyT7tNwkVdS-"
      },
      "source": [
        "訓練時間\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_t-JsKxUViFy",
        "outputId": "8e999f73-a670-42c1-f687-4f604693327c"
      },
      "source": [
        "print(f\"total time is {end-start} sec\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total time is 1745.8250839710236 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2HaGRVEYGQS"
      },
      "source": [
        "## 測試"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 548
        },
        "id": "5yFuUKKRYH73",
        "outputId": "659a3439-3a0f-4e10-f366-3947c34e10e4"
      },
      "source": [
        "agent = Agent(state_size=8, action_size=4, seed=543)\n",
        "\n",
        "agent.qnetwork_local.load_state_dict(torch.load('checkpoint.pth'))\n",
        "NUM_OF_TEST = 5 # Do not revise it !!!!!\n",
        "test_total_reward = []\n",
        "action_list = []\n",
        "for i in range(NUM_OF_TEST):\n",
        "  actions = []\n",
        "  state = env.reset()\n",
        "  total_reward = 0\n",
        "\n",
        "  done = False\n",
        "  while not done:\n",
        "      action, _ = agent.act(state)\n",
        "      actions.append(action)\n",
        "      state, reward, done, _ = env.step(action)\n",
        "\n",
        "      total_reward += reward\n",
        "\n",
        "      #img.set_data(env.render(mode='rgb_array'))\n",
        "      #display.display(plt.gcf())\n",
        "      #display.clear_output(wait=True)\n",
        "  print(total_reward)\n",
        "  test_total_reward.append(total_reward)\n",
        "\n",
        "  action_list.append(actions) #儲存你測試的結果\n",
        "  print(\"length of actions is \", len(actions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-cd19736f4e2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m       \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m       \u001b[0mactions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m       \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-55b1f297a83f>\u001b[0m in \u001b[0;36mact\u001b[0;34m(self, state, eps)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqnetwork_local\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0maction_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqnetwork_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqnetwork_local\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-a0c2efe1c47c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;34m\"\"\"Build a network that maps state -> action values.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1751\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1753\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibility"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aex7mcKr0J01",
        "outputId": "3ff8f2d3-ac28-47d0-d68a-a63e374a958f"
      },
      "source": [
        "print(f\"Your final reward is : %.2f\"%np.mean(test_total_reward))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your final reward is : nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leyebGYRpqsF"
      },
      "source": [
        "Action list 的長相"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hGAH4YWDpp4u",
        "outputId": "57d71de0-16cc-4cf3-97e5-6e292f00fe67"
      },
      "source": [
        "print(\"Action list looks like \", action_list)\n",
        "print(\"Action list's shape looks like \", np.shape(action_list))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Action list looks like  [[1, 3, 3, 0, 3, 3, 2, 3, 1, 0, 0, 1, 2, 3, 3, 0, 2, 2, 0, 3, 0, 2, 0, 2, 3, 2, 2, 0, 2, 1, 0, 3, 3, 1, 1, 3, 2, 2, 3, 2, 2, 1, 2, 3, 1, 1, 1, 0, 3, 2, 3, 2, 2, 3, 0, 0, 3, 1, 2, 3, 2, 1, 1, 0, 0, 2, 3, 2, 3, 0, 3, 2, 2, 1, 2, 3, 3, 1, 1, 0, 3, 3, 0, 2, 3, 2], [2, 2, 0, 0, 3, 2, 2, 0, 2, 2, 2, 2, 2, 3, 1, 3, 0, 0, 1, 1, 1, 0, 3, 2, 2, 2, 1, 0, 2, 0, 2, 1, 1, 2, 0, 3, 0, 0, 3, 1, 1, 2, 0, 0, 2, 3, 3, 0, 0, 0, 2, 1, 0, 2, 1, 2, 1, 2, 2, 1, 3, 2, 3, 2, 2, 2, 2, 0, 1, 0, 2, 0, 0, 2, 2, 1, 0, 3, 1, 3, 3, 2, 2, 1, 3, 0, 3, 2, 3, 3, 3, 2, 1, 0, 1, 1, 3, 2, 0, 3, 2, 2, 2, 2, 3, 1, 0, 3, 1, 3, 2, 0, 1, 2, 3, 0, 2, 2, 3, 1, 2, 2, 3, 2, 1, 3, 3, 2, 1, 0, 2, 3, 2, 3, 3, 2, 2, 0, 2, 3, 3, 2, 0, 2, 1, 2, 3, 3, 2, 2, 2, 2, 3, 3, 2, 3, 2, 3, 1, 0, 3, 3, 2, 0, 1, 2, 0], [2, 2, 2, 1, 3, 2, 0, 0, 2, 3, 0, 0, 2, 2, 2, 2, 1, 1, 2, 0, 0, 0, 2, 2, 2, 0, 2, 1, 3, 3, 2, 3, 2, 3, 2, 0, 1, 3, 0, 2, 0, 0, 0, 1, 2, 3, 2, 2, 3, 0, 3, 0, 0, 3, 3, 3, 3, 3, 0, 1, 2, 3, 0, 0, 3, 1, 3, 2, 3, 2, 2, 2, 3, 2, 0, 3, 0, 0, 1, 3, 3, 3, 3, 3, 0, 0, 0, 2, 2, 0, 2, 3, 3, 2, 3, 3, 3, 2, 3, 1, 2, 0, 3, 3, 3, 3, 3, 0, 0, 3, 2, 3, 1], [0, 0, 3, 2, 2, 0, 0, 3, 1, 2, 3, 3, 0, 2, 3, 2, 2, 0, 0, 2, 3, 0, 3, 3, 3, 3, 3, 3, 2, 3, 3, 2, 1, 1, 3, 2, 2, 1, 3, 1, 0, 0, 2, 2, 0, 2, 3, 3, 1, 1, 2, 1, 1, 2, 2, 3, 0, 1, 1, 0, 0, 1, 0, 3, 0, 3, 3, 3, 1, 2, 2, 2, 3, 2, 2, 0, 2, 3, 2, 1], [1, 3, 3, 1, 0, 1, 2, 0, 2, 0, 0, 0, 0, 2, 0, 1, 2, 3, 2, 2, 3, 0, 2, 1, 2, 2, 2, 1, 3, 3, 1, 0, 1, 1, 2, 1, 2, 3, 1, 2, 0, 2, 3, 1, 2, 3, 3, 3, 1, 0, 3, 3, 3, 2, 2, 3, 1, 2, 3, 3, 3, 2, 1, 0, 1, 0, 3, 0, 3, 2, 3, 0, 0, 0, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 2, 0, 2, 0, 2, 1, 2]]\n",
            "Action list's shape looks like  (5,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7sokqEUtrFY"
      },
      "source": [
        "Action 的分布\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WHdAItjj1nxw",
        "outputId": "f1ce3ded-e68c-435a-fddc-bcd367e133c1"
      },
      "source": [
        "distribution = {}\n",
        "for actions in action_list:\n",
        "  for action in actions:\n",
        "    if action not in distribution.keys():\n",
        "      distribution[action] = 1\n",
        "    else:\n",
        "      distribution[action] += 1\n",
        "print(distribution)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{1: 87, 3: 162, 0: 116, 2: 172}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ricE0schY75M"
      },
      "source": [
        "儲存 Model Testing的結果\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GZsMkGmIY42b",
        "outputId": "e7b44580-d745-4836-93f1-dcf2a9af0bba"
      },
      "source": [
        "PATH = \"Action_List_test.npy\" # 可以改成你想取的名字或路徑\n",
        "np.save(PATH ,np.array(action_list))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asK7WfbkaLjt"
      },
      "source": [
        "### 你要交到JudgeBoi的檔案94這個\n",
        "儲存結果到本地端 (就是你的電腦裡拉 = = )\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "c-CqyhHzaWAL",
        "outputId": "c643cb29-bd23-4aff-b256-34f92fca5210"
      },
      "source": [
        "from google.colab import files\n",
        "files.download(PATH)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_fd06fb03-f302-48f4-ac69-3e59def5be65\", \"Action_List_test.npy\", 1381)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seT4NUmWmAZ1"
      },
      "source": [
        "# Server 測試\n",
        "到時候下面會是我們Server上測試的環境，可以給大家看一下自己的表現如何"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "U69c-YTxaw6b",
        "outputId": "5688624f-47df-492e-88b1-ce5653190b8b"
      },
      "source": [
        "action_list = np.load(PATH,allow_pickle=True) #到時候你上傳的檔案\n",
        "seed = 543 #到時候測試的seed 請不要更改\n",
        "fix(env, seed)\n",
        "\n",
        "agent.network.eval()  # 測試前先將 network 切換為 evaluation 模式\n",
        "\n",
        "test_total_reward = []\n",
        "for actions in action_list:\n",
        "  state = env.reset()\n",
        "  img = plt.imshow(env.render(mode='rgb_array'))\n",
        "\n",
        "  total_reward = 0\n",
        "\n",
        "  done = False\n",
        "  # while not done:\n",
        "  done_count = 0\n",
        "  for action in actions:\n",
        "      # action, _ = agent1.sample(state)\n",
        "      state, reward, done, _ = env.step(action)\n",
        "      done_count += 1\n",
        "      total_reward += reward\n",
        "      if done:\n",
        "\n",
        "        break\n",
        "    #   img.set_data(env.render(mode='rgb_array'))\n",
        "    #   display.display(plt.gcf())\n",
        "    #   display.clear_output(wait=True)\n",
        "  print(f\"Your reward is : %.2f\"%total_reward)\n",
        "  test_total_reward.append(total_reward)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/__init__.py:422: UserWarning: torch.set_deterministic is deprecated and will be removed in a future release. Please use torch.use_deterministic_algorithms instead\n",
            "  \"torch.set_deterministic is deprecated and will be removed in a future \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Your reward is : -311.62\n",
            "Your reward is : -207.13\n",
            "Your reward is : -367.00\n",
            "Your reward is : -386.09\n",
            "Your reward is : -171.29\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjFBWwQP1hVe"
      },
      "source": [
        "# 你的成績"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GpJpZz3Wbm0X",
        "outputId": "90aa2866-a3f0-430e-c15a-072b68a46594"
      },
      "source": [
        "print(f\"Your final reward is : %.2f\"%np.mean(test_total_reward))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your final reward is : -288.63\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUBtYXG2eaqf"
      },
      "source": [
        "## 參考資料\n",
        "\n",
        "以下是一些有用的參考資料。\n",
        "建議同學們實做前，可以先參考第一則連結的上課影片。\n",
        "在影片的最後有提到兩個有用的 Tips，這對於本次作業的實做非常有幫助。\n",
        "\n",
        "- [DRL Lecture 1: Policy Gradient (Review)](https://youtu.be/z95ZYgPgXOY)\n",
        "- [ML Lecture 23-3: Reinforcement Learning (including Q-learning) start at 30:00](https://youtu.be/2-JNBzCq77c?t=1800)\n",
        "- [Lecture 7: Policy Gradient, David Silver](http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching_files/pg.pdf)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGqP2EU1joWM"
      },
      "source": []
    }
  ]
}